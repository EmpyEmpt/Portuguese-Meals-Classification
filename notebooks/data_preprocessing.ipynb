{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portugese Meals Classification: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import clear_output\n",
    "import yaml\n",
    "import albumentations as A\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GigaFolder\\projects\\Portuguese-Meals-Classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('config.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config['dataset']['csv_dir'] + 'full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(config['dataset']['data_dir'])\n",
    "classes.sort()\n",
    "\n",
    "\n",
    "def print_class_count(df, name: str, ret=False):\n",
    "    counts = {}\n",
    "    print(f'{name} CLASS COUNTS:\\n')\n",
    "    for cls in classes:\n",
    "        count = df[\"label\"].where(df[\"label\"] == cls).dropna().count()\n",
    "        counts[cls] = count\n",
    "        print(f'{cls:20s} : {count}')\n",
    "\n",
    "    print(f'\\nTotal samples: {len(counts)}')\n",
    "    if ret:\n",
    "        return counts\n",
    "\n",
    "\n",
    "class_counts = print_class_count(df, 'Initial', True)\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.copy()\n",
    "assert len(df) == len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6836"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first of all - duplicate (twice) underrepresented classes (~30 ex.)\n",
    "for idx in range(len(a)):\n",
    "    cls, path = a.iloc[idx]\n",
    "    if class_counts[cls] < 50:\n",
    "        a = a.append({'label': cls, 'path': path}, ignore_index=True)\n",
    "        a = a.append({'label': cls, 'path': path}, ignore_index=True)\n",
    "\n",
    "clear_output()\n",
    "len(a)\n",
    "# now there're ~60-90 examples of examples of under represented classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I'll remove around 250 examples of overrepresented classes\n",
    "b = a.copy()\n",
    "for idx in range(len(a)):\n",
    "    cls, path = a.iloc[idx]\n",
    "    if b[\"label\"].where(b[\"label\"] == cls).dropna().count() > 250:\n",
    "        b = b.drop(b[b.path == path].index)\n",
    "\n",
    "clear_output()\n",
    "len(b)\n",
    "# now there 250 examples of over-represented classes\n",
    "# (60-90)underrepresented, 200aletria, 250overrepresented, 100normaly distibuted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 of processing CLASS COUNTS:\n",
      "\n",
      "aletria              : 234\n",
      "arroz_cabidela       : 97\n",
      "bacalhau_bras        : 250\n",
      "bacalhau_natas       : 97\n",
      "batatas_fritas       : 250\n",
      "bolo_chocolate       : 250\n",
      "cachorro             : 250\n",
      "caldo_verde          : 69\n",
      "cozido_portuguesa    : 104\n",
      "croissant            : 96\n",
      "donuts               : 250\n",
      "esparguete_bolonhesa : 250\n",
      "feijoada             : 99\n",
      "francesinha          : 250\n",
      "gelado               : 250\n",
      "hamburguer           : 250\n",
      "jardineira           : 98\n",
      "nata                 : 98\n",
      "ovo                  : 96\n",
      "pasteis_bacalhau     : 111\n",
      "pizza                : 250\n",
      "tripas_moda_porto    : 107\n",
      "waffles              : 250\n",
      "\n",
      "Total samples: 23\n"
     ]
    }
   ],
   "source": [
    "print_class_count(b, 'Step 1 of processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(b, random_state=config['random_seed'])\n",
    "del a\n",
    "del b\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = A.Compose(\n",
    "    [\n",
    "        A.Rotate(limit=25, p=1),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 9), p=0.6),\n",
    "        A.RandomBrightnessContrast(p=0.4),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def resize(image, image_size=config['img_shape'][0]):\n",
    "    # I'll go for a square image\n",
    "    return cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def augment(image):\n",
    "    return transformation(image=image)['image']\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    image = image / 255\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    image = augment(image)\n",
    "    image = resize(image)\n",
    "    image = normalize(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "clear_output()\n",
    "for idx in range(len(df)):\n",
    "    cls, path = df.iloc[idx]\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    im1 = preprocess(image)\n",
    "\n",
    "    labels.append(cls)\n",
    "    images.append(im1)\n",
    "\n",
    "    if not (cls == 'aletria' or class_counts[cls] >= 250):\n",
    "        im2 = preprocess(image)\n",
    "\n",
    "        image = resize(image)\n",
    "        image = normalize(image)\n",
    "\n",
    "        labels.append(cls)\n",
    "        labels.append(cls)\n",
    "\n",
    "        images.append(im2)\n",
    "        images.append(image)\n",
    "\n",
    "len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aletria' '234']\n",
      " ['arroz_cabidela' '291']\n",
      " ['bacalhau_bras' '250']\n",
      " ['bacalhau_natas' '291']\n",
      " ['batatas_fritas' '250']\n",
      " ['bolo_chocolate' '250']\n",
      " ['cachorro' '250']\n",
      " ['caldo_verde' '207']\n",
      " ['cozido_portuguesa' '312']\n",
      " ['croissant' '288']\n",
      " ['donuts' '250']\n",
      " ['esparguete_bolonhesa' '250']\n",
      " ['feijoada' '297']\n",
      " ['francesinha' '250']\n",
      " ['gelado' '250']\n",
      " ['hamburguer' '250']\n",
      " ['jardineira' '294']\n",
      " ['nata' '294']\n",
      " ['ovo' '288']\n",
      " ['pasteis_bacalhau' '333']\n",
      " ['pizza' '250']\n",
      " ['tripas_moda_porto' '321']\n",
      " ['waffles' '250']]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(labels)\n",
    "u, c = np.unique(arr, return_counts=True)\n",
    "print(np.asarray((u, c)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "labels = np.asarray(labels)\n",
    "labels = encoder.fit_transform(labels)\n",
    "\n",
    "images = np.asarray(images, dtype = np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_splits(X, Y, dir):\n",
    "    np.savez_compressed(dir + 'Xvalues.npz', X)\n",
    "    np.savez_compressed(dir + 'Yvalues.npz', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_splits(images, labels, config['dataset']['augmented_dir'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20f5b49acdb8aa5482bf611cd625371fff780f4a1ea28b5df1442e16c229ca99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
